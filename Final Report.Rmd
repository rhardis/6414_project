---
title: "Wines - Final Report"
author: "Richard Hardis, Paulina Jane LoCicero, James Trawick"
date: "12/1/2019"
output:
  word_document: default
  html_document: default
toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# ISYE 6414 Final Project: Regression Analysis of Wines

## Summary
***
  Our goal is to evaluate factors that influence wine quality and price, based on a dataset collected from https://www.kaggle.com/zynicide/wine-reviews, which was scraped from WineEnthusiast in June of 2017, then again in November 2017 (https://www.winemag.com/?s=&drink_type=wine).  We augmented this dataset with several other geographical and textual predictors to help further explore the drivers of wine price and quality.  Winery latitude, longitude, and elevation were gathered from the the mapquest Open APIs.  Temperature and Precipitation data for countries was gathered from the WorldBank’s open climate API. The foundational winemag.com data set contains information for 130,000 different wines, some of the factors include: country, description, and designation among others.  Length of review was also calculated for each wine to use as a potentially significant predictor.  Due to API limitations, we are randomly sampling 2000 wines from the original 130,000 to use for data cleaning and then build our model. With this data, we hope to answer the following questions:
Under which conditions does higher wine rating correspond with higher reviews?  Specifically, with which predicting variables included in a model does that model show rating being a statistically significant predictor of price? How accurate is a multiple linear regression model built off of the winemag.com 2017 dataset at predicting the prices of the top 20 wines of 2019 according to totalwine.com? Do some regions produce wines with higher quality (how does region influence points awarded?). We intend to run an initial simple linear regression, a multiple linear regression, an ANOVA test, and will evaluate other models which may fit the data well based on our initial findings. Finally, our team will also explore robust regression methodologies (lasso, elastic net, etc…) in order to identify important attributes and reduce overfitting in for our predictive models.

## Background
***
### Study Motivations
  We want to know more about wine...
  
### Study Expectations
  Wine price and quality are related and can be explained better with the help of other variables
  
## Data
***
### Raw Data and Collection
  Our raw data started from a root dataset of wines taken from https://www.kaggle.com/zynicide/wine-reviews as part of their machine learning competition.  This dataset contains wine data for over 130,000 distinct wines and was scraped from the search results pages of winemag.com in June and November of 2017.  The original dataset contained country, description, designation, points (quality score), price, province (state in the US or province in Europe), region_1, region_2 (subregion of the province or region_1), taster_name, taster_twitter_handle, title, variety, and winery.  This dataset had many data points, but did not have many useful predictors for regression analysis, so we chose to scrape further webpages to gather more factors.  Two datasets were developed with additional factors.  The first large dataset has predictors  review length (word count), year produced, abv (alcohol by volume), bottle_size, category (red, white, rose), and importer scraped from the individual wine page on winemag.com.  This large dataset has 73,256 individual wines.  The second, smaller dataset contains all of the features of the large dataset and also includes average country temperature, standard deviation of country temperature, average country precipitation, standard deviation of country precipitation, lattitude, longitude, and elevation.  There are 1123 unique wines in this smaller dataset.  Winery latitude, longitude, and elevation were gathered from the the mapquest Open APIs.  Temperature and Precipitation data for countries was gathered from the WorldBank’s open climate API.  The large quantity of data requires detailed exploration to ensure its quality and suitability for regression analysis.
  
### Data Exploration
  The first step in the data exploration is cleaning. This involved removing any wines that did not have data for price, quality, year,temperature, precipitation, elevation, review length, abv, bottle size, or importer.  Because of the large quantity of data available, this approach of removing wines with missing data is preferable to imputing using averages or other means.  Next, data exploration of the data can commence.
  
```{r echo=FALSE}
# Read in the data
setwd("~/GitHub/6414_project/")
large_data = read.csv("datasets/large_wines_nonan.csv")
small_data = read.csv("datasets/small_wines_nonan.csv")
```

```{r echo=FALSE}
# subset the data columns
large_data = large_data[,c(1,4,5,6,14,16,17,18,19)]
large_data$category = as.factor(large_data$category)
small_data = small_data[,c(1,4,5,6,11,21,22,23,25,26)]
small_data$category = as.factor(small_data$category)
```

  The first step in exploring the data is checking how the data are distrubted and how each factor varies with all other factors.  Upon basic exploration it can be found that the variable Bottle Size does not vary as all wines were judged in 750ml bottles. This variable is removed because it does not vary.  Next, outliers need to be examined and dealt with.

First, box plots will be used to find outliers.  Outliers are then removed. For example, wines with alcohol contents above 50%, prices above $200, and year produced outside of the years 2000-2020 were removed from the data. Additionally, only red, white, and rose wines are considered.

```{r, echo=FALSE, warning=FALSE}
library(dplyr)
abv_limit = 50
small_data = small_data %>% filter(abv<abv_limit & price<200 & year>2000 & year<2020 & elevation>0  & (category=='Red' | category=='White' | category=='Rose'))
large_data = large_data %>% filter(abv<abv_limit & price<200 & year>2000 & year<2020 & (category=='Red' | category=='White' | category=='Rose'))

library(cowplot)
library(ggplot2)
# Basic box plot
p1 = ggplot(small_data, aes(x=category, y=price)) + 
  geom_boxplot()+theme(text = element_text(size=11), axis.text.x = element_text(angle=90, hjust=1))
p2 = ggplot(large_data, aes(x=category, y=price)) + 
  geom_boxplot()+theme(text = element_text(size=11), axis.text.x = element_text(angle=90, hjust=1))
p3 = ggplot(small_data, aes(x=category, y=points)) + 
  geom_boxplot()+theme(text = element_text(size=11), axis.text.x = element_text(angle=90, hjust=1))
p4 = ggplot(large_data, aes(x=category, y=points)) + 
  geom_boxplot()+theme(text = element_text(size=11), axis.text.x = element_text(angle=90, hjust=1))
p5 = ggplot(small_data, aes(x=category, y=elevation)) + 
  geom_boxplot()+theme(text = element_text(size=11), axis.text.x = element_text(angle=90, hjust=1))

plot_grid(p1, p2, p3, p4, p5, labels = c('Small', 'Large','Small', 'Large', 'Small'), label_size = 10)
```


```{r}
attach(small_data)
par(mfrow = c(2, 3))
hist(points, main = "Histogram of Points", xlab = "Wine Score", col = 2)
hist(price, main = "Histogram of Price", xlab = "Wine Price", col = 3)
hist(abv, main = "Histogram of Alcohol by Volume", xlab = "ABV (%)", col = 5)
hist(year, main = "Histogram of Year Produced", xlab = "Year", col = 8)
hist(review_length, main = "Histogram of Review Length", xlab = "Word Count", col = 9)

attach(large_data)
par(mfrow = c(2, 3))
hist(points, main = "Histogram of Points", xlab = "Wine Score", col = 2)
hist(price, main = "Histogram of Price", xlab = "Wine Price", col = 3)
hist(abv, main = "Histogram of Alcohol by Volume", xlab = "ABV (%)", col = 5)
hist(year, main = "Histogram of Year Produced", xlab = "Year", col = 8)
hist(review_length, main = "Histogram of Review Length", xlab = "Word Count", col = 9)
```



```{r}
library(GGally)
ggpairs(large_data[,c(-1,-4,-7)], progress = FALSE)
```

```{r}
ggpairs(small_data[,c(-1,-4,-10)], progress = FALSE)
```

  Cook's distance for each dataset is examined next.
  
```{r}
model1 = lm(price~., data=small_data[,c(-1,-4,-10)])
cook = cooks.distance(model1)
plot(cook, type="h", lwd=3, col="red", ylab = "Cook's Distance", main="Cook's Distance")
sdcook = cbind(small_data, cook)
sdcook2 = sdcook %>% filter(cook<.005)
sdcook2 = sdcook2[,c(-1,-4,-10)]
model2 = lm(price~.,data=sdcook2)
cutoff = 4/(nrow(small_data))
plot(model2, which=4, cook.levels=cutoff)
print(cutoff)
```

```{r}
model3 = lm(price~., data=large_data[,c(-1,-4,-7)])
cook = cooks.distance(model3)
plot(cook, type="h", lwd=3, col="red", ylab = "Cook's Distance", main="Cook's Distance")
ldcook = cbind(large_data, cook)
ldcook2 = ldcook %>% filter(cook<.005)
ldcook2 = ldcook2[,c(-1,-4,-10)]
model4 = lm(price~.,data=ldcook2)
cutoff = 4/(nrow(large_data))
plot(model4, which=4, cook.levels=cutoff)
```

```{r}
large_data = ldcook2
small_data = sdcook2
```


## Modeling Analyses
***
### Model Approach 1: Multiple Linear Regression
  MLR with variable selection and metric analyses (r^2, adj. r^2, assumptions, etc.)

### Model Approach 2: Poisson Regression
  Poisson model with variable selection and metric analyses (r^2, adj. r^2, GOF, assumptions, etc.)

## Conclusions
***
### Implications
  What did we find?

### Further Questions
  What's next?
